{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['grid', 'S', 'background', 'background_dict'])\n"
     ]
    }
   ],
   "source": [
    "data_dict = torch.load('../../data/summarized_neutron_data_w_bkg_260meV_ML.pt')\n",
    "print(data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sqw import SpecNeuralRepr\n",
    "model_sqw = SpecNeuralRepr.load_from_checkpoint('input/version_14896845/checkpoints/epoch=7160-step=343728.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import NeighborDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hklw_grid = torch.vstack([_.unsqueeze(0) for _ in torch.meshgrid(*[v for k, v in data_dict['grid'].items()], indexing='ij')]).permute(1, 2, 3, 4, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import lightning\n",
    "# from src.kernel import KernelNet\n",
    "# from src.siren import SirenNet\n",
    "\n",
    "# class L_Kernel(lightning.LightningModule):\n",
    "#     def __init__(self, forward_model, dim=3, neighbor_range=1, exclude_corner=True):\n",
    "#         super().__init__()\n",
    "#         # self.save_hyperparameters()\n",
    "        \n",
    "#         self.dim = dim\n",
    "#         self.neighbor_range = neighbor_range\n",
    "#         self.exclude_corner = exclude_corner\n",
    "        \n",
    "#         self.kernel_net = KernelNet(\n",
    "#             dim=dim, neighbor_range=neighbor_range, \n",
    "#             exclude_corner=exclude_corner)\n",
    "#         self.bkgd_net = SirenNet(\n",
    "#                 dim_in = dim,\n",
    "#                 dim_hidden = self.kernel_net.hidden_dim,\n",
    "#                 dim_out = 1,\n",
    "#                 num_layers = self.kernel_net.num_layers,\n",
    "#                 w0_initial = 30.,\n",
    "#                 final_activation = torch.nn.ReLU()\n",
    "#         )\n",
    "#         self.forward_model = forward_model\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         return self.kernel_net(x)\n",
    "    \n",
    "#     def compute_metrics_on_batch(self, batch):\n",
    "#         kappa = self.forward(\n",
    "#             batch['center_pts'].to(self.dtype).to(self.device))\n",
    "#         neighb_data = self.forward_model.forward_qw(\n",
    "#             batch['neighb_pts'].to(self.dtype).to(self.device))\n",
    "#         s_sig = torch.einsum(\n",
    "#             'ij, ij -> i', \n",
    "#             kappa, neighb_data[:,self.kernel_net.kernel_mask_flat]\n",
    "#         ).unsqueeze(-1)\n",
    "#         # s_pred = s_sig\n",
    "#         s_bkg = self.bkgd_net(batch['center_pts'].to(self.dtype).to(self.device))\n",
    "#         s_pred = s_sig + s_bkg\n",
    "#         s_target = batch['center_data']\n",
    "#         loss_reconst = torch.nn.functional.mse_loss(s_pred.cpu(), s_target.cpu())\n",
    "#         loss_bkg_mag = 1e-2 * s_bkg.pow(2).mean()\n",
    "#         # loss = loss_reconst + loss_bkg_mag\n",
    "#         return loss_reconst, loss_bkg_mag\n",
    "    \n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         loss_reconst, loss_bkg_mag = self.compute_metrics_on_batch(batch)\n",
    "#         loss = loss_reconst + loss_bkg_mag\n",
    "#         self.log('train_reconst', loss_reconst.item(), prog_bar=True)\n",
    "#         self.log('train_bkg_mag', loss_bkg_mag.item(), prog_bar=True)\n",
    "#         self.log('train_loss', loss.item(), prog_bar=True)\n",
    "#         return loss\n",
    "    \n",
    "#     def validation_step(self, batch, batch_idx):\n",
    "#         loss_reconst, loss_bkg_mag = self.compute_metrics_on_batch(batch)\n",
    "#         loss = loss_reconst + loss_bkg_mag\n",
    "#         self.log('val_reconst', loss_reconst.item(), prog_bar=True)\n",
    "#         self.log('val_bkg_mag', loss_bkg_mag.item(), prog_bar=True)\n",
    "#         self.log('val_loss', loss.item(), prog_bar=True)\n",
    "    \n",
    "#     def configure_optimizers(self):\n",
    "#         optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "#         return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import NeighborDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NeighborDataset(hklw_grid, data_dict['S'], neighbor_range=3)\n",
    "dataloader = DataLoader(dataset, batch_size=5000, shuffle=True, num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.kernel import L_Kernel\n",
    "\n",
    "loss_bkg_mag_weight = 5e-2\n",
    "model_config = {\n",
    "    'dim': 4,\n",
    "    'neighbor_range': 3,\n",
    "    'exclude_corner': True,\n",
    "    'hidden_dim': 256, \n",
    "    'num_layers': 3, \n",
    "    'scale_factor_initial': 'none'\n",
    "}\n",
    "\n",
    "model_sqw.params = torch.tensor([29.0, 1.68])\n",
    "L_model = L_Kernel(forward_model=model_sqw, model_config=model_config, loss_bkg_mag_weight=loss_bkg_mag_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/pscratch/sd/z/zhantao/conda/inxs/lib/python3.9/site-packages/lightning/pytorch/trainer/configuration_validator.py:71: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type           | Params\n",
      "-------------------------------------------------\n",
      "0 | kernel_net    | KernelNet      | 1.8 M \n",
      "1 | bkgd_net      | SirenNet       | 133 K \n",
      "2 | forward_model | SpecNeuralRepr | 529 K \n",
      "-------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.671     Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 359/359 [04:47<00:00,  1.25it/s, v_num=1, train_reconst=1.600, train_bkg_mag=1.040, train_loss=2.640]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 359/359 [04:47<00:00,  1.25it/s, v_num=1, train_reconst=1.600, train_bkg_mag=1.040, train_loss=2.640]\n"
     ]
    }
   ],
   "source": [
    "import lightning\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "from lightning.pytorch.strategies import DDPStrategy\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "# logger = TensorBoardLogger(\"./lightning_logs\", name=f\"sf_{model_config['scale_factor_initial']:.1f}\")\n",
    "logger = TensorBoardLogger(\"./lightning_logs\", name=f\"sf_net\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    every_n_train_steps=10, save_last=True, save_top_k=1, monitor=\"train_loss\",\n",
    "    filename=f\"sf_{model_config['scale_factor_initial']}-{{epoch}}-{{step}}\"\n",
    ")\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# ddp = DDPStrategy(process_group_backend=\"nccl\")\n",
    "trainer = lightning.Trainer(\n",
    "    max_epochs=15, accelerator='gpu', logger=logger,\n",
    "    callbacks=[checkpoint_callback, TQDMProgressBar(refresh_rate=10)],\n",
    "    log_every_n_steps=1, devices=1, sync_batchnorm = True,\n",
    "    enable_checkpointing=True, default_root_dir='./')\n",
    "\n",
    "\n",
    "trainer.fit(L_model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inxs",
   "language": "python",
   "name": "inxs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
